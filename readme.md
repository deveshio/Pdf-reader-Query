# ğŸ“„ CogniDoc: AI-Powered Document Query System

**Live Demo:** [cognidoc.netlify.app](https://cognidoc.netlify.app)

CogniDoc is a full-stack, AI-powered web application that transforms static PDF documents into interactive conversational partners. Users can upload a PDF and ask questions in natural language to receive intelligent, context-aware answers generated by a sophisticated AI pipeline.

---

## âœ¨ Demo

The application provides a clean, two-step user experience:

1. **Before Upload:** A clean interface prompts the user to upload a file.  
![Demo Screenshot](https://github.com/deveshio/Pdf-reader-Query/blob/main/media/image1.png)

2. **After Upload & Query:** After processing, the app confirms the document is ready and provides an interface for asking questions and receiving AI-generated answers.
![Demo Screenshot](https://github.com/deveshio/Pdf-reader-Query/blob/main/media/image1.png)
---

## ğŸš€ Key Features

- **Dynamic PDF Upload:** Users can upload any PDF document for analysis.  
- **AI-Powered Q&A:** Leverages a Retrieval-Augmented Generation (RAG) pipeline to provide accurate, context-aware answers.  
- **Decoupled Full-Stack Architecture:** Built with a separate React frontend and a FastAPI backend for scalability and maintainability.  
- **Persistent Vector Storage:** Utilizes Astra DB to store document embeddings for efficient, low-latency semantic searches.  
- **Real-time Semantic Search:** Finds the most relevant parts of the document to answer a user's question, no matter how itâ€™s phrased.

---

## ğŸ› ï¸ Tech Stack

| **Category** | **Technology** |
|---------------|----------------|
| **Frontend** | React.js |
| **Backend** | FastAPI, Python |
| **AI / NLP** | LangChain, Google Gemini API (Answer Generation), Hugging Face (Embeddings) |
| **Database** | Astra DB (Vector Store) |
| **Deployment** | Netlify (Frontend), Render (Backend), Git |

---

## ğŸ“‚ Project Structure

```
cognidoc/
â”‚
â”œâ”€â”€ ğŸ“‚ backend/
â”‚ â”œâ”€â”€ ğŸ“„ main.py             # FastAPI application logic
â”‚ â”œâ”€â”€ ğŸ“„ requirements.txt    # Python dependencies for the backend
â”‚ â”œâ”€â”€ ğŸ“„ .env                # Secret keys for local development
â”‚ â””â”€â”€ ğŸ“„ .gitignore          # Ignores .venv, .env, and pycache
â”‚
â”œâ”€â”€ ğŸ“‚ frontend/
â”‚ â”œâ”€â”€ ğŸ“‚ public/
â”‚ â”‚ â””â”€â”€ ğŸ“„ index.html        # Main HTML page for the React app
â”‚ â”‚
â”‚ â”œâ”€â”€ ğŸ“‚ src/
â”‚ â”‚ â”œâ”€â”€ ğŸ“‚ components/
â”‚ â”‚ â”‚ â”œâ”€â”€ ğŸ“„ FileUploader.js # File upload UI component
â”‚ â”‚ â”‚ â””â”€â”€ ğŸ“„ QueryForm.js    # Question form component
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ ğŸ“‚ services/
â”‚ â”‚ â”‚ â””â”€â”€ ğŸ“„ api.js          # Handles all API calls to the backend
â”‚ â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ ğŸ“„ App.js            # Main component orchestrating the UI
â”‚ â”‚ â”œâ”€â”€ ğŸ“„ App.css           # Styles for the App component
â”‚ â”‚ â”œâ”€â”€ ğŸ“„ index.js          # Entry point for the React app
â”‚ â”‚ â””â”€â”€ ğŸ“„ index.css         # Global styles
â”‚ â”‚
â”‚ â”œâ”€â”€ ğŸ“„ package.json        # Frontend dependencies
â”‚ â”œâ”€â”€ ğŸ“„ package-lock.json   # Locks dependency versions
â”‚ â””â”€â”€ ğŸ“„ .gitignore          # Ignores node_modules, build files.
â”‚
â””â”€â”€ ğŸ“„ README.md             # Project documentation

```
---

## âš™ï¸ How It Works: The RAG Pipeline

CogniDoc is built around a **Retrieval-Augmented Generation (RAG)** pipeline, ensuring that the AIâ€™s answers are grounded in the uploaded document.

### **1. Upload & Processing (`/upload` endpoint):**

- The user uploads a PDF via the React frontend.  
- The file is sent to the FastAPI backend.  
- The backend extracts all text from the PDF.  
- The text is split into smaller, manageable chunks using LangChain.  
- Each chunk is converted into a numerical representation (vector embedding) using a Hugging Face sentence-transformer model.  
- These embeddings are stored in the Astra DB vector store.

### **2. Query & Answer Generation (`/query` endpoint):**

- The user asks a question in the React frontend.  
- The question is sent to the FastAPI backend.  
- The backend performs a semantic search in Astra DB to find the most relevant text chunks.  
- These chunks, along with the original question, are passed as context to the **Google Gemini API**.  
- The Gemini model generates a comprehensive, human-like answer based on the provided context.  
- The final answer is sent back to the React frontend and displayed to the user.

---

## ğŸ Getting Started: Running the Project Locally

To run this project locally, set up both the backend and frontend.

### **Prerequisites**
- Node.js (v18 or newer)  
- Python 3.11 or newer  
- Git for cloning the repository  
- API keys for Google Gemini and Astra DB

---

### **1. Clone the Repository**

```bash
git clone https://github.com/deveshio/Pdf-reader-Query.git
cd cognidoc
```
### ***2. Backend Setup***
```
# navigate to backend 
cd backend

# Use py -3.11 or python3.11 depending on your system
py -3.11 -m venv .venv
.\.venv\Scripts\activate

# Install the requirements
pip install -r requirements.txt

```

Configure your secrets by creating a .env
```
GOOGLE_AI_KEY="your_google_api_key_here"
ASTRA_DB_APPLICATION_TOKEN="your_astra_token_here"
ASTRA_DB_ID="your_astra_db_id_here"
```

Run the backend server.
```
uvicorn main:app --reload
```

### ***2. Backend Setup***
```
# navigate to Frontend
cd frontned

# Install dependencies:
npm install

# run the dev environment
npm start

```


## ğŸ™ Thank You

Thank you for taking the time to read through this project and for using **CogniDoc** wisely.

If you have any **feature updates or improvements** in mind, Iâ€™d be happy to review your **pull requests** and collaborate to make the project even better!
